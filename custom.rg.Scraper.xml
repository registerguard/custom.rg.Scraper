<?xml version="1.0" encoding="UTF-8"?>
<Export generator="Cache" version="22">
<Class name="custom.rg.Scraper">
<Description><![CDATA[
<p><b>Scrapes given URI and stores scraping fragment in database.</b></p>
<p><b>Dependacies:</b> DTI's common (dtCommon.inc) macros.</p>
<p>Developed by Micky Hulse for <a href="http://www.registerguard.com">The Register-Guard</a>.</p>
<p>Please visit <a href="https://github.com/mhulse/custom.rg.Scraper">GitHub</a> for more information and/or to get the latest version of this code.</p>
<p>Big ups to DTI's Eric Gauthier! Thanks for the <a href="https://groups.google.com/d/topic/dti-lightning/hagUO0vUq0c/discussion">pro help</a> Eric!</p>
<p>TODO:</p>
<ol>
<li>Write accessor methods? For example: set interval after $normalize; return scraping with HTML unescaped; other?</li>
<li>Use TRY/CATCH? Not sure of best way to handle this.</li>
<li>What's faster/easier than $SYSTEM.SQL.DATEDIFF?</li>
</ol>]]></Description>
<IncludeCode>dtCommon</IncludeCode>
<Super>%Persistent</Super>
<TimeCreated>62151,42765.80179</TimeCreated>

<Property name="name">
<Description><![CDATA[
<p><b>Name</b> of scraping "fragment" (required).</p>]]></Description>
<Type>%String</Type>
<Required>1</Required>
<SqlColumnNumber>2</SqlColumnNumber>
<Parameter name="MAXLEN" value="255"/>
</Property>

<Property name="interval">
<Description><![CDATA[
<p><b>Interval</b> of scraping in minutes (required).</p>]]></Description>
<Type>%Integer</Type>
<Required>1</Required>
<SqlColumnNumber>3</SqlColumnNumber>
<Parameter name="MAXVAL" value="525600"/>
<Parameter name="MINVAL" value="1"/>
</Property>

<Property name="first">
<Description><![CDATA[
<p><b>First</b> time scraped (required).</p>]]></Description>
<Type>%TimeStamp</Type>
<Required>1</Required>
<SqlColumnNumber>4</SqlColumnNumber>
</Property>

<Property name="scraped">
<Description><![CDATA[
<p><b>Date/time</b> of last scraping (required).</p>]]></Description>
<Type>%TimeStamp</Type>
<Required>1</Required>
<SqlColumnNumber>5</SqlColumnNumber>
</Property>

<Property name="counter">
<Description><![CDATA[
<p><b>Counts</b> how many times scraping has been updated.</p>]]></Description>
<Type>%Integer</Type>
<Required>1</Required>
<SqlColumnNumber>6</SqlColumnNumber>
</Property>

<Property name="scraping">
<Description><![CDATA[
<p><b>Contents</b> of scraping.</p>]]></Description>
<Type>%Stream.GlobalCharacter</Type>
<SqlColumnNumber>7</SqlColumnNumber>
</Property>

<Property name="uri">
<Description><![CDATA[
<p><b>URI</b> of scraping (required).</p>]]></Description>
<Type>%String</Type>
<Required>1</Required>
<SqlColumnNumber>8</SqlColumnNumber>
<Parameter name="MAXLEN" value="1024"/>
</Property>

<Index name="IDKEY">
<Description><![CDATA[
<p><b>Note:</b> IdKey can't be updated; you need to delete and re-insert the row.</p>]]></Description>
<IdKey>1</IdKey>
<Properties>name</Properties>
</Index>

<Method name="scrape">
<Description><![CDATA[
<p><b>Parameters:</b></p>
<ul>
<li><b>name:</b> <i>(Required)</i> Scraping fragment identifier.</li>
<li><b>server:</b> <i>(Required)</i> The IP address or machine name of the web server that you wish to connect to.<b>*</b></li>
<li><b>location:</b> Name of item to retrieve from the web server.<b>*</b></li>
<li><b>interval:</b> Time, in minutes, of scraping interval. <b>Default:</b> 60 minutes.</li>
<li><b>force:</b> Force scraping fragment update? <b>Default:</b> False (0).</li>
<li><b>userAgent:</b> The User-Agent request-header field contains information about the user agent originating the request.<b>*</b></li>
<li><b>followRedirect:</b> If true then automatically follow redirection requests from the web server. <b>Default:</b> False (0).<b>*</b></li>
<li><b>https:</b> If not using a proxy server and this is true then it issues a request for an https page rather than the normal http page. <b>Default:</b> False (0).<b>*</b></li>
<li><b>authorization:</b> Sets/get the 'Authorization:' header field in the Http request.<b>*</b></li>
<li><b>contentEncoding:</b> Sets/gets the 'Content-Encoding:' entity header field in the HTTP request.<b>*</b></li>
<li><b>contentType:</b> Sets/gets the 'Content-Type:' entity header field in the HTTP request. <b>Default:</b> "text/html".<b>*</b></li>
<li><b>contentCharset:</b> If the ContentType starts with 'text/' then this is the charset to encode the contents with. <b>Default:</b> UTF-8.<b>*</b></li>
<li><b>port:</b> The TCP/IP port number to connect to. <b>Default:</b> 80.<b>*</b></li>
<li><b>pragma:</b> The Pragma general-header field is used to include implementation- specific directives that may apply to any recipient along the request/response chain.<b>*</b></li>
</ul>
<p><b>*</b> See <class>%Net.HttpRequest</class> for more info.</p>]]></Description>
<ClassMethod>1</ClassMethod>
<FormalSpec>name:%String="",server:%String="",location:%String="",interval:%Integer=60,force:%Boolean=0,userAgent:%String="",followRedirect:%Boolean=0,https:%Boolean=0,authorization:%String="",contentEncoding:%String="",contentType:%String="text/html",contentCharset:%String="UTF-8",port:%Integer=80,pragma:%String=""</FormalSpec>
<ReturnType>%String</ReturnType>
<Implementation><![CDATA[
	; Initialize variables:
	set return  = ""    // Return string.
	set sc      = $$$OK // Status code.
	set stream  = ""    // DT global character stream.
	set scraper = ""    // Stream from database.
	set http    = ""    // Net http request.
	set uri     = ""    // URI of scraping.
	
	; Make sure interval is a whole number:
	set interval = $normalize(interval, -1) // When scale=-1, num is truncated to an integer value.
	
	; Name/server required:
	if ($length(name) && $length(server) && (interval > 0)) {
		
		; Initialize global character stream object:
		//set stream = ##class(%Stream.GlobalCharacter).%New()
		set stream = ##class(dt.common.streams.GlobalCharacterStream).%New() // https://groups.google.com/d/topic/dti-lightning/hagUO0vUq0c/discussion
		
		; Open the Scraper object:
		set scraper = ..%OpenId(name,, .sc)
		
		; IF there's a status error ($isobject(scraper) would also work) OR an expired object OR force is true:
		if ($$$ISERR(sc) || ($isobject(scraper) && scraper.expired()) || force) {
			
			; Re-initialize:
			set sc = $$$OK
		
			; %Net.HttpRequest stuff:
			set http = ##class(%Net.HttpRequest).%New()
			set http.Server = server
			set:($length(location)) http.Location = location // Note the location does not contain a leading '/' character as this is implicit.
			set:($length(userAgent)) http.UserAgent = userAgent
			//set:($length(params)) http.Params = params // Appears to be useless: http://tinyurl.com/4gpyvx7
			set:(followRedirect) http.FollowRedirect = followRedirect
			set:(https) http.Https = https
			set:($length(authorization)) http.Authorization = authorization
			set:($length(contentEncoding)) http.ContentEncoding = contentEncoding
			set http.ContentType = contentType
			set http.ContentCharset = contentCharset
			set http.Port = port
			set:($length(pragma)) http.Pragma = pragma
			//set http.XXXX = xxxxxxx
		
			; Get the request:
			set sc = http.Get()
		
			; Was the request "fulfilled"?
			if ($$$ISOK(sc) && (http.HttpResponse.StatusCode = 200)) {
			
				; Populate character stream:
				do stream.Write(##class(%CSP.Page).EscapeHTML(http.HttpResponse.Data.Read()))
			
				; Build request URI:
				set uri = $case(http.Https, 1:"https", :"http") _ "://" _ http.Server _ $case(http.Port, 80:"", :":" _ http.Port) _ $zstrip(location, "<", "/") // Should I EscapeURL too?
				
				; Validate interval:
				set:(interval > 525600) interval = 525600 // (24 * 60) * 365 = 525600 minutes/year.
				
				; Updating an existing entry?
				if ($isobject(scraper)) {
				
					; Yes:
					set scraper.interval = interval
					set scraper.scraped = $zdatetime($horolog, 3)
					set scraper.counter = scraper.counter + 1
					//set scraper.scraping = stream
					set sc = scraper.scraping.CopyFrom(stream)
					set scraper.uri = uri
				
				} else {
				
					; No:
					set scraper = ..%New()
					set scraper.name = name
					set scraper.interval = interval
					set (scraper.first, scraper.scraped) = $zdatetime($horolog, 3)
					set scraper.counter = 1
					//set scraper.scraping = stream
					set sc = scraper.scraping.CopyFrom(stream)
					set scraper.uri = uri
				
				}
				
				; Save:
				set sc = scraper.%Save()
				$$$dtThrow(sc, "Failed to save '" _ $get(name) _ "'.")
				
				; Return current scraping:
				set stream = scraper.scraping
				
			} else {
				
				; Previous scraping:
				set:($isobject(scraper)) stream = scraper.scraping _ $char(10) _ $char(10)
				
				; Append the status code and reason:
				do stream.Write("<!-- Status code: " _ http.HttpResponse.StatusCode _ ", Reason: " _ http.HttpResponse.ReasonPhrase _ " -->")
			
			}
		
		} else {
		
			; Current scraping:
			set stream = scraper.scraping	
		
		}
		
		; Unescape the HTML:	
		set return = ##class(%CSP.Page).UnescapeHTML(stream.Read())
		
	}
	
	; Return scraping:
	quit return
]]></Implementation>
</Method>

<Method name="expired">
<Description><![CDATA[
<p>
Checks if scraping has expired.
<br>
Boolean return value.
</p>]]></Description>
<ReturnType>%Boolean</ReturnType>
<Implementation><![CDATA[
	set return = 0
	set:(##this.diff() >= ##this.interval) return = 1
	quit return
]]></Implementation>
</Method>

<Method name="diff">
<Description><![CDATA[
<p>Time difference since last scraping to now in minutes.
<br>
See <class>%SYSTEM.SQL</class>'s DATEDIFF ClassMethod for more info.
</p>]]></Description>
<FormalSpec>datepart:%String="mi"</FormalSpec>
<ReturnType>%Integer</ReturnType>
<Implementation><![CDATA[	quit $SYSTEM.SQL.DATEDIFF(datepart, ##this.scraped, $horolog)
]]></Implementation>
</Method>

<Method name="age">
<Description><![CDATA[
<p>
Time since very first scraping.
<br>
See <class>%SYSTEM.SQL</class>'s DATEDIFF ClassMethod for more info.
</p>]]></Description>
<FormalSpec>datepart:%String="mi"</FormalSpec>
<ReturnType>%Integer</ReturnType>
<Implementation><![CDATA[	quit $SYSTEM.SQL.DATEDIFF(datepart, ##this.first, $horolog)
]]></Implementation>
</Method>

<Method name="next">
<Description><![CDATA[
<p>Time until next scraping in minutes.</p>]]></Description>
<ReturnType>%Integer</ReturnType>
<Implementation><![CDATA[
	set return = ##this.interval - ##this.diff()
	set:(return <= 0) return = 0 // We don't want negative numbers.
	quit return
]]></Implementation>
</Method>

<Method name="elapsed">
<Description><![CDATA[
<p>Elapsed time, in minutes, since last update.</p>]]></Description>
<ReturnType>%Integer</ReturnType>
<Implementation><![CDATA[	quit ##this.interval - ##this.next()
]]></Implementation>
</Method>

<Storage name="Default">
<Type>%Library.CacheStorage</Type>
<DataLocation>^custom.rg.ScraperD</DataLocation>
<DefaultData>ScraperDefaultData</DefaultData>
<IdLocation>^custom.rg.ScraperD</IdLocation>
<IndexLocation>^custom.rg.ScraperI</IndexLocation>
<StreamLocation>^custom.rg.ScraperS</StreamLocation>
<Data name="ScraperDefaultData">
<Value name="1">
<Value>%%CLASSNAME</Value>
</Value>
<Value name="2">
<Value>interval</Value>
</Value>
<Value name="3">
<Value>first</Value>
</Value>
<Value name="4">
<Value>scraped</Value>
</Value>
<Value name="5">
<Value>counter</Value>
</Value>
<Value name="6">
<Value>scraping</Value>
</Value>
<Value name="7">
<Value>uri</Value>
</Value>
</Data>
</Storage>
</Class>
</Export>
